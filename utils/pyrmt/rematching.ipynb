{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "import os\n",
    "from PyRMT import RMTMesh\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from visual_utils import *\n",
    "from icp_utils import *\n",
    "\n",
    "#from evaluation import *\n",
    "\n",
    "def visu(vertices):\n",
    "    \n",
    "    \"The function normalizes the values over the vertices\"\n",
    "    \n",
    "    min_coord,max_coord = np.min(vertices,axis=0,keepdims=True),np.max(vertices,axis=0,keepdims=True)\n",
    "    cmap = (vertices-min_coord)/(max_coord-min_coord)\n",
    "    return cmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFM.mesh import TriMesh\n",
    "target_re = TriMesh(r'D:\\Make_Galileo_great_again\\data\\giorgio_\\MNI_remesh.off')\n",
    "target_hr = TriMesh(r'D:\\Make_Galileo_great_again\\data\\giorgio_\\MNI.off', area_normalize=True, center= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh(target_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_re.vertlist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SamplesDir = r\"D:\\Make_Galileo_great_again\\data\\giorgio_\"\n",
    "\n",
    "N_meshes = 0\n",
    "m_list=[]\n",
    "m_rem_list=[]\n",
    "bm_list=[]\n",
    "\n",
    "for i in range(N_meshes):\n",
    "    v, f = igl.read_triangle_mesh(os.path.join(SamplesDir, fr\"0000{i:02d}_tumoredbrain\\0000{i:02d}_tumoredbrain.off\"))\n",
    "    v = np.asfortranarray(v)\n",
    "    f = np.asfortranarray(f)\n",
    "\n",
    "    m = RMTMesh(v, f)\n",
    "    m.make_manifold()\n",
    "    m_list.append(m)\n",
    "\n",
    "    m_rem = m.remesh(6000)\n",
    "    m_rem.clean_up()\n",
    "    m_rem_list.append(m_rem)\n",
    "\n",
    "    bm = m_rem.baryc_map(v)\n",
    "    bm_list.append(bm)\n",
    "    \n",
    "    igl.write_triangle_mesh(os.path.join(SamplesDir, fr\"00000{i:02d}_tumoredbrain.off\"), m_rem.vertices, m_rem.triangles)\n",
    "\n",
    "v, f = igl.read_triangle_mesh(r\"D:\\Make_Galileo_great_again\\data\\giorgio_\\MNI.off\")\n",
    "v = np.asfortranarray(v)\n",
    "f = np.asfortranarray(f)\n",
    "\n",
    "m = RMTMesh(v, f)\n",
    "m.make_manifold()\n",
    "m_rem = m.remesh(6000)\n",
    "m_rem.clean_up()\n",
    "bm = m_rem.baryc_map(v)\n",
    "igl.write_triangle_mesh(os.path.join(SamplesDir, \"MNI_remesh.off\"), m_rem.vertices, m_rem.triangles)\n",
    "savemat(os.path.join(SamplesDir, \"MNI_remesh.mat\"), {\"U\" : bm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFM.mesh import TriMesh\n",
    "\n",
    "m0= TriMesh(m_list[0].vertices, m_list[0].triangles)\n",
    "m0_rem=TriMesh(m_rem_list[0].vertices, m_rem_list[0].triangles)\n",
    "m1 = TriMesh(m_list[1].vertices, m_list[1].triangles)\n",
    "m1_rem = TriMesh(m_rem_list[1].vertices, m_rem_list[1].triangles)\n",
    "m2 = TriMesh(m_list[2].vertices, m_list[2].triangles)\n",
    "m2_rem = TriMesh(m_rem_list[2].vertices, m_rem_list[2].triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_KNN = knn_query_normals(m0.vertlist, m0_rem.vertlist,\n",
    "                                            m0.vertex_normals, m0_rem.vertex_normals,\n",
    "                                            k_base=20, n_jobs=20, verbose=False)\n",
    "#p2p_KNN = knn_query(meshlist[0].vertlist, meshlist[1].vertlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh(m0, color=np.mean(m0.vertices,axis=1))\n",
    "plot_mesh(m0_rem, color=np.mean(m0.vertices,axis=1)[p2p_KNN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_KNN = knn_query_normals(m0.vertlist, m0_rem.vertlist,\n",
    "                                            m0.vertex_normals, m0_rem.vertex_normals,\n",
    "                                            k_base=20, n_jobs=20, verbose=False)\n",
    "#p2p_KNN = knn_query(meshlist[0].vertlist, meshlist[1].vertlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p2p_KNN = knn_query(m0_rem.vertlist, m1_rem.vertlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh(m0_rem, color=np.mean(m0_rem.vertices,axis=1))\n",
    "plot_mesh(m1_rem, color=np.mean(m0_rem.vertices,axis=1)[p2p_KNN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p2p_KNN = knn_query_normals(m0_rem.vertlist, m2_rem.vertlist,\n",
    "#                                            m0_rem.vertex_normals, m2_rem.vertex_normals,\n",
    "#                                            k_base=20, n_jobs=20, verbose=False)\n",
    "p2p_KNN = knn_query(m0_rem.vertlist, m2_rem.vertlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh(m0_rem, color=np.mean(m0_rem.vertices,axis=1))\n",
    "plot_mesh(m2_rem, color=np.mean(m0_rem.vertices,axis=1)[p2p_KNN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZOOMOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyFM.spectral as spectral\n",
    "from pyFM.FMN import FMN\n",
    "import pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFM.refine.zoomout import mesh_zoomout_refine_p2p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Laplacian basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0_rem.process(k=150,intrinsic=True)\n",
    "m2_rem.process(k=150,intrinsic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply ZoomOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply zoomout starting from the Knn initialization\n",
    "FM_12_zo, p2p_ZO = mesh_zoomout_refine_p2p(p2p_21=p2p_KNN, mesh1=m0_rem, mesh2=m2_rem, k_init=20, nit=26, step=5, return_p2p=True, n_jobs=10, verbose=True)\n",
    "\n",
    "plot_mesh(m0_rem,color=np.mean(m0_rem.vertices,axis=1))\n",
    "plot_mesh(m2_rem,color=np.mean(m0_rem.vertices,axis=1)[p2p_ZO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import original meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 min e 11 sec.\n",
    "import trimesh\n",
    "#Number of meshes to import:\n",
    "N_meshes= 3\n",
    "meshlist=[]\n",
    "for i in range(N_meshes):\n",
    "    meshlist.append(TriMesh(fr'D:\\Make_Galileo_great_again\\data\\giorgio_\\0000{i:02d}_tumoredbrain\\0000{i:02d}_tumoredbrain.off')) \n",
    "    mesh= trimesh.Trimesh(meshlist[i].vertices, meshlist[i].faces)\n",
    "    components = mesh.split(only_watertight=False)\n",
    "    largest_component = max(components, key=lambda comp: comp.volume) \n",
    "    print(f\"Number of vertices before LC for mesh{i:02d}:\", meshlist[i].vertices.shape)\n",
    "    #meshlist[i]= TriMesh(largest_component.vertices, largest_component.faces).process(k=200, intrinsic=True)\n",
    "    #print(f\"Number of vertices after LC for mesh{i:02d}:\", meshlist[i].vertices.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondence with upscaled FMap + Transferring function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_RM = spectral.FM_to_p2p(FM_12_zo, bm_list[0] @ m0_rem.eigenvectors, bm_list[2] @ m2_rem.eigenvectors, n_jobs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh(meshlist[0],color=np.mean(meshlist[0].vertices,axis=1))\n",
    "plot_mesh(meshlist[2],color=np.mean(meshlist[0].vertices,axis=1)[p2p_RM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rematching with FunctionalMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = np.zeros((3, 10), dtype=int)\n",
    "for i in tqdm(range(3)):\n",
    "    subsample_list[i] = meshlist[i].extract_fps(10, geodesic=False, verbose=False)\n",
    "fps1 = subsample_list[0]\n",
    "fps2 = subsample_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial correspondences with KNN\n",
    "p2p_21_init_sub = knn_query_normals(meshlist[0].vertlist[fps1], meshlist[2].vertlist[fps2],\n",
    "                                            meshlist[0].vertex_normals[fps1], meshlist[2].vertex_normals[fps2],\n",
    "                                            k_base=5, n_jobs=20, verbose=False)\n",
    "# ICP Align the shape\n",
    "_, R, t = icp_align(meshlist[2].vertlist[fps2], meshlist[0].vertlist[fps1],\n",
    "                            p2p_12=p2p_21_init_sub,\n",
    "                            return_params=True, n_jobs=20, epsilon=1e-4, verbose=False)\n",
    "\n",
    "meshlist[2].rotate(R)\n",
    "meshlist[2].translate(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rematching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_list_tri=[m0_rem, m1_rem, m2_rem]\n",
    "\n",
    "SRC=0\n",
    "TRG=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = np.zeros((3, 10), dtype=int)\n",
    "for i in tqdm(range(3)):\n",
    "    subsample_list[i] = rem_list_tri[i].extract_fps(10, geodesic=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps2 = knn_query(rem_list_tri[TRG].vertlist, rem_list_tri[SRC].vertlist[subsample_list[SRC]])\n",
    "\n",
    "landmarks=np.array([subsample_list[SRC],fps2]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFM.functional import FunctionalMapping\n",
    "\n",
    "process_params = {\n",
    "        'n_ev': (20,20),  # Number of eigenvalues on source and Target\n",
    "        'landmarks': landmarks,\n",
    "        'subsample_step': 1,  # In order not to use too many descriptors\n",
    "        'n_descr': 40, #number of descriptors\n",
    "        'descr_type': 'HKS',  # WKS or HKS\n",
    "    }\n",
    "model = FunctionalMapping(rem_list_tri[SRC],rem_list_tri[TRG])\n",
    "model.preprocess(**process_params,verbose=False)\n",
    "\n",
    "model.fit(w_descr= 1e-1, w_lap= 1e-3, w_dcomm= 1,w_orient= 0, verbose=False)\n",
    "fmap12=model.FM       #C{XY}, or A_{YX}^T\n",
    "\n",
    "#p2p=model.get_p2p(fmap12, model.mesh1.eigenvectors[:,:k],model.mesh2.eigenvectors[:,:k],adj, bijective)\n",
    "p2p=model.get_p2p()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(fmap12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap1 = np.mean(visu(rem_list_tri[SRC].vertlist),axis=1)\n",
    "#cmap2_wks = cmap1[p2p]\n",
    "\n",
    "plot_mesh(rem_list_tri[SRC],color=np.mean(rem_list_tri[SRC].vertices,axis=1))\n",
    "plot_mesh(rem_list_tri[TRG],color=np.mean(rem_list_tri[SRC].vertices,axis=1)[p2p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zoomout\n",
    "from pyFM.refine.zoomout import mesh_zoomout_refine_p2p\n",
    "FM_12_hks_zo, p2p_21_hks_zo = mesh_zoomout_refine_p2p(p2p_21=p2p, mesh1=rem_list_tri[SRC], mesh2=rem_list_tri[TRG], k_init=20, nit=16, step=5, return_p2p=True, n_jobs=10, verbose=True)\n",
    "\n",
    "#cmap1 = np.mean(visu(rem_list_tri[SRC].vertlist),axis=1)\n",
    "#cmap2_wks = cmap1[p2p_21_wks_zo]\n",
    "\n",
    "\n",
    "plot_mesh(rem_list_tri[SRC],color=np.mean(rem_list_tri[SRC].vertices,axis=1))\n",
    "plot_mesh(rem_list_tri[TRG],color=np.mean(rem_list_tri[SRC].vertices,axis=1)[p2p_21_hks_zo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(FM_12_hks_zo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_ZO_RM = spectral.FM_to_p2p(FM_12_hks_zo, bm_list[SRC] @ rem_list_tri[SRC].eigenvectors, bm_list[TRG] @ rem_list_tri[TRG].eigenvectors, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh(meshlist[SRC],color=np.mean(meshlist[SRC].vertices,axis=1))\n",
    "plot_mesh(meshlist[TRG],color=np.mean(meshlist[SRC].vertices,axis=1)[p2p_ZO_RM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRANIOFACIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'D:\\Make_Galileo_great_again')\n",
    "from utils.Morpho import *\n",
    "\n",
    "sys.path.append('./pyFM/')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pyFM.spectral as spectral\n",
    "from pyFM.mesh import TriMesh\n",
    "from pyFM.FMN import FMN\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "SamplesDir = r\"D:\\Make_Galileo_great_again\\data\\giorgio_\"\n",
    "maps_dict={}\n",
    "N_meshes=51\n",
    "\n",
    "m_list= []\n",
    "m_rem_list= []\n",
    "bm_list= []\n",
    "\n",
    "#meshes in Trimesh\n",
    "meshlist= []\n",
    "rem_list_tri = []\n",
    "\n",
    "#Dictionary where Fun Maps are stored.\n",
    "maps_dict = {}\n",
    "\n",
    "for i in range(N_meshes):\n",
    "    \n",
    "    PATH = os.path.join(SamplesDir, \"remeshed\", fr\"0000{i:02d}_tumoredbrain.off\")\n",
    "    print(fr\"0000{i:02d}_tumoredbrain\\0000{i:02d}_tumoredbrain.off\")\n",
    "    PATH_hr = os.path.join(SamplesDir, fr\"0000{i:02d}_tumoredbrain\\0000{i:02d}_tumoredbrain.off\")\n",
    "    PATH_bm = os.path.join(SamplesDir, \"bm\", fr\"bm{i:02d}.mat\")\n",
    "\n",
    "    if os.path.exists(PATH):\n",
    "\n",
    "        rem_list_tri.append(TriMesh(PATH, area_normalize=True, center= True).process(k=110, intrinsic=True))\n",
    "        meshlist.append(TriMesh(PATH_hr, area_normalize=True, center= True))\n",
    "    #print(\"Mesh\" , i, \"loaded\")\n",
    "\n",
    "target_hr = TriMesh(r'D:\\Make_Galileo_great_again\\data\\giorgio_\\MNI.off', area_normalize=True, center= True)\n",
    "meshlist.append(target_hr)\n",
    "target_re = TriMesh(r'D:\\Make_Galileo_great_again\\data\\giorgio_\\MNI_remesh.off', area_normalize=True, center= True).process(k=110, intrinsic=True)\n",
    "rem_list_tri.append(target_re)\n",
    "\n",
    "#for i in range (N_meshes):\n",
    "#    PATH_SAVE= os.path.join(SamplesDir, fr\"FM\\fmap12{i:02d}.npy\")\n",
    "#    FM_12_hks_zo=np.load(PATH_SAVE)\n",
    "#    maps_dict[3,i]= FM_12_hks_zo.copy()\n",
    "#    maps_dict[i,3]= FM_12_hks_zo.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_chosen_pairs = 2500  # Number of pairs to select in the network\n",
    "k_init = 20  # Initial size of functional maps. We recommand around 20 but because of the double surface we need 50\n",
    "n_subsample = 3000 # Number of samples to use for initial maps\n",
    "\n",
    "print(f'{int(scipy.special.binom(N_meshes, 2)):d} possible pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "all_pairs = list(itertools.combinations(np.arange(N_meshes), 2))\n",
    "rng.shuffle(all_pairs)\n",
    "\n",
    "chosen_pairs = all_pairs[:n_chosen_pairs]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(np.arange(N_meshes))\n",
    "G.add_edges_from(chosen_pairs)\n",
    "\n",
    "\n",
    "print(f'Is G connected ? {nx.is_connected(G)}')\n",
    "all_cliques= nx.enumerate_all_cliques(G)\n",
    "triad_cliques=[x for x in all_cliques if len(x)==3 ]\n",
    "print(f'G has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges')\n",
    "print(f'G has {len(triad_cliques)} 3-cycles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = np.zeros((N_meshes, n_subsample), dtype=int)\n",
    "for i in tqdm(range(len(rem_list_tri)-1)):\n",
    "    print(i)\n",
    "    subsample_list[i] = rem_list_tri[i].extract_fps(n_subsample, geodesic=False, verbose=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_dict = {}\n",
    "\n",
    "for pair_ind, (i, j) in enumerate(tqdm(chosen_pairs)):\n",
    "    \n",
    "    \n",
    "    fps1 = subsample_list[i]\n",
    "    fps2 = subsample_list[j]\n",
    "    \n",
    "       \n",
    "\n",
    "    mesh1 = copy.deepcopy(rem_list_tri[i])\n",
    "    mesh2 = copy.deepcopy(rem_list_tri[j])\n",
    "\n",
    "    # Get initial correspondences\n",
    "    p2p_21_init_sub = knn_query_normals(mesh1.vertlist[fps1], mesh2.vertlist[fps2],\n",
    "                                                mesh1.vertex_normals[fps1], mesh2.vertex_normals[fps2],\n",
    "                                                k_base=20, n_jobs=10, verbose=False)\n",
    "    \n",
    "    # ICP Align the shape\n",
    "    _, R, t = icp_align(mesh2.vertlist[fps2], mesh1.vertlist[fps1],\n",
    "                                p2p_12=p2p_21_init_sub,\n",
    "                                return_params=True, n_jobs=10, epsilon=1e-4, verbose=False)\n",
    "\n",
    "    mesh2.rotate(R);\n",
    "    mesh2.translate(t);\n",
    "    \n",
    "    # Get final correspondences\n",
    "    p2p_21 = knn_query_normals(mesh1.vertlist[fps1], mesh2.vertlist[fps2],\n",
    "                                        mesh1.vertex_normals[fps1], mesh2.vertex_normals[fps2],\n",
    "                                        k_base=20, n_jobs=10)\n",
    "    \n",
    "    p2p_12 = knn_query_normals(mesh2.vertlist[fps2], mesh1.vertlist[fps1],\n",
    "                                        mesh2.vertex_normals[fps2], mesh1.vertex_normals[fps1],\n",
    "                                        k_base=20, n_jobs=10)\n",
    "        \n",
    "    # Compute initial functional maps\n",
    "    FM_12 = spectral.mesh_p2p_to_FM(p2p_21, rem_list_tri[i], rem_list_tri[j], dims=k_init, subsample=(fps1, fps2))\n",
    "    FM_21 = spectral.mesh_p2p_to_FM(p2p_12, rem_list_tri[j], rem_list_tri[i], dims=k_init, subsample=(fps2, fps1))\n",
    "    maps_dict[(i,j)] = FM_12.copy();\n",
    "    maps_dict[(j,i)] = FM_21.copy();\n",
    "    \n",
    "print(f'{len(maps_dict.keys())} maps computed');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = FMN(rem_list_tri[:11], maps_dict=maps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "czo_parameters = {\n",
    "    'nit': (110-k_init)//5,\n",
    "    'step': 5,\n",
    "    'cclb_ratio': .8,\n",
    "    'subsample': subsample_list,\n",
    "    'isometric': False,\n",
    "    'verbose': True,\n",
    "    'weight_type': 'iscm',\n",
    "    'n_jobs': 15,\n",
    "}\n",
    "\n",
    "\n",
    "network.zoomout_refine(**czo_parameters)\n",
    "\n",
    "network.compute_W(M=110)\n",
    "network.compute_CCLB(int(.8*network.M), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compute_W(M=105)\n",
    "network.compute_CCLB(int(.8*network.M), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.cclb_eigenvalues[:,None][0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_from_id_a = np.zeros(network.n_meshes)\n",
    "deviation_from_id_cr = np.zeros(network.n_meshes)\n",
    "for i in range(network.n_meshes):\n",
    "    CSD_a, CSD_c = network.get_CSD(i)\n",
    "    deviation_from_id_a[i] = np.linalg.norm(CSD_a - np.eye(CSD_a.shape[0]))\n",
    "    deviation_from_id_cr[i] = np.linalg.norm(np.sqrt(network.cclb_eigenvalues[:,None]) * (CSD_c - np.eye(CSD_c.shape[0]))) / np.sqrt(network.cclb_eigenvalues.sum())\n",
    "\n",
    "    \n",
    "deviation_from_id_cr.argmin(), deviation_from_id_cr.argmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_meshind = deviation_from_id_cr.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_displacement = 100\n",
    "backend = 'gpu' # OR \"cpuù\n",
    "from pyFM.FMN import FMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LB_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyFM\n",
    "mesh1 = copy.deepcopy(network.meshlist[base_meshind]) # TriMesh(network.meshlist[base_meshind].path, area_normalize=True).process(k=k_displacement,verbose=True)\n",
    "LB_1 = network.get_LB(base_meshind, complete=True)  # (n_1',m)\n",
    "\n",
    "displacements = np.zeros((network.n_meshes, 3*mesh1.n_vertices))\n",
    "displacements_red = np.zeros((network.n_meshes, 3*k_displacement))\n",
    "\n",
    "for meshind2 in tqdm(range(network.n_meshes)):\n",
    "    if meshind2 == base_meshind:\n",
    "        continue\n",
    "    \n",
    "    mesh2 = copy.deepcopy(network.meshlist[meshind2])\n",
    "    LB_2 = network.get_LB(meshind2, complete=True)  # (n_2',m)\n",
    "    \n",
    "    #p2p_czo_12 = knn_query(torch.from_numpy(LB_2.astype(np.float32)).cuda(), torch.from_numpy(LB_1.astype(np.float32)).cuda(), backend=backend).cpu().numpy()\n",
    "\n",
    "    p2p_czo_12 = knn_query(LB_2.astype(np.float32), LB_1.astype(np.float32))\n",
    "\n",
    "    R, t = rigid_alignment(mesh1.vertlist, mesh2.vertlist, p2p_12=p2p_czo_12,\n",
    "                                 return_params=True, return_deformed=False, weights=mesh1.vertex_areas)\n",
    "    \n",
    "    \n",
    "    mesh2 = TriMesh(mesh2.vertlist, mesh2.facelist)\n",
    "    mesh2.translate(-t)\n",
    "    mesh2.rotate(np.linalg.inv(R))\n",
    "    \n",
    "    tau_czo = mesh1.project(mesh2.vertlist[p2p_czo_12] - mesh1.vertlist, k=k_displacement)\n",
    "    \n",
    "    displacements[meshind2] = mesh1.decode(tau_czo).flatten()\n",
    "    displacements_red[meshind2] = tau_czo.flatten()\n",
    "print('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_disp = np.mean(displacements_red,axis=0)\n",
    "pca_d = PCA(n_components=5)\n",
    "emb_d_red = pca_d.fit_transform(displacements_red - avg_disp[None,:])\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.title('Explained variance ratio')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance (%)')\n",
    "plt.plot(np.arange(1+pca_d.n_components) , 100*np.cumsum(np.concatenate([[0],pca_d.explained_variance_ratio_])), marker=\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,2] # list of labels for each skulls\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reglin1 = LogisticRegression(penalty='none', fit_intercept=True, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglin1.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
